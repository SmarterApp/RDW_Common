package org.opentestsystem.rdw.archive;

import com.amazonaws.AmazonServiceException;
import com.amazonaws.SdkClientException;
import com.amazonaws.auth.AWSStaticCredentialsProvider;
import com.amazonaws.auth.BasicAWSCredentials;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.AmazonS3ClientBuilder;
import com.amazonaws.services.s3.Headers;
import com.amazonaws.services.s3.model.CopyObjectRequest;
import com.amazonaws.services.s3.model.DeleteObjectsRequest;
import com.amazonaws.services.s3.model.ListObjectsV2Request;
import com.amazonaws.services.s3.model.ListObjectsV2Result;
import com.amazonaws.services.s3.model.ObjectListing;
import com.amazonaws.services.s3.model.ObjectMetadata;
import com.amazonaws.services.s3.model.S3ObjectSummary;
import com.amazonaws.util.IOUtils;
import com.google.common.base.CharMatcher;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.util.StreamUtils;

import java.io.BufferedInputStream;
import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import static java.util.stream.Collectors.toList;

/**
 * An {@link ArchiveService} implementation that uses Amazon S3.
 */
public class S3ArchiveService implements ArchiveService {
    private static final Logger logger = LoggerFactory.getLogger(S3ArchiveService.class);
    private static final String S3SchemePrefix = "s3://";
    private static final String Delimiter = "/";

    private final AmazonS3 amazonS3;
    private final String bucket;
    private final String sse;
    private final String pathPrefix;

    public S3ArchiveService(final ArchiveProperties archiveProperties) {
        if (!archiveProperties.isConfiguredS3()) {
            throw new IllegalArgumentException("Invalid S3 root " + archiveProperties.getUriRoot());
        }

        this.amazonS3 = AmazonS3ClientBuilder.standard()
                .withRegion(archiveProperties.getS3RegionStatic())
                .withCredentials(
                        new AWSStaticCredentialsProvider(
                                new BasicAWSCredentials(
                                        archiveProperties.getS3AccessKey(),
                                        archiveProperties.getS3SecretKey()
                                )
                        )
                )
                .build();

        // just in case there is an errant trailing slash ...
        this.bucket = stripTrailingSlash(
                archiveProperties.getUriRoot().substring(S3SchemePrefix.length())
        );

        this.sse = archiveProperties.getS3Sse();

        this.pathPrefix = archiveProperties.getPathPrefix() != null
                ? stripTrailingSlash(archiveProperties.getPathPrefix())
                : "";

        if (!amazonS3.doesBucketExist(bucket)) {
            throw new IllegalArgumentException("Invalid S3 bucket " + bucket);
        }
    }

    private String stripTrailingSlash(String path) {
        return path.endsWith(Delimiter) ? path.substring(0, path.length() - 1) : path;
    }

    private String prefixedLocation(String location) {
        if (this.pathPrefix.isEmpty()) {
            return location;
        }
        return this.pathPrefix + Delimiter + location;
    }

    private String removeLocationPrefix(String location) {
        if (this.pathPrefix.isEmpty()) {
            return location;
        }
        return location.replace(this.pathPrefix + Delimiter, "");
    }

    @Override
    public String getRawUri(final String location) {
        return S3SchemePrefix + bucket + Delimiter + prefixedLocation(location);
    }

    @Override
    public List<String> listResources(final String locationPrefix) {
        final List<String> resourcePaths = new ArrayList<>();
        try {
            final ListObjectsV2Request request = new ListObjectsV2Request()
                    .withBucketName(bucket)
                    .withPrefix(prefixedLocation(locationPrefix));


            // Amazon S3 paginates so keep requesting data until entire listing is received
            ListObjectsV2Result result;
            do {
                result = amazonS3.listObjectsV2(request);

                for (final S3ObjectSummary summary : result.getObjectSummaries()) {
                    resourcePaths.add(removeLocationPrefix(summary.getKey()));
                }

                // If there are more than maxKeys keys in the bucket, get a continuation token
                // and list the next objects.
                request.setContinuationToken(result.getNextContinuationToken());

            } while (result.isTruncated());

        } catch (final AmazonServiceException exception) {
            // The call was transmitted successfully, but Amazon S3 couldn't process
            // it, so it returned an error response.
            throw new RuntimeException(exception);
        } catch (final SdkClientException exception) {
            // Amazon S3 couldn't be contacted for a response, or the client
            // couldn't parse the response from Amazon S3.
            throw new RuntimeException(exception);
        }

        return resourcePaths;
    }

    @Override
    public void writeResource(final String location, final byte[] content, Properties properties) {
        if (properties == null) {
            properties = new Properties();
        }
        properties.put(Headers.CONTENT_LENGTH, (long) content.length);
        //delegating to alternate writeResource, don't modify location
        writeResource(location, new ByteArrayInputStream(content), properties);
    }

    @Override
    public void writeResource(final String location, final InputStream is, final Properties properties) {
        final String prefixedLocation = prefixedLocation(location);
        final ObjectMetadata metadata = mapPropertiesToObjectMetadata(properties);
        final boolean lengthKnown = (metadata.getContentLength() > 0);

        // it baffles me why this isn't part of the AmazonS3Client configuration
        // but it's not, so set the SSE algorithm in the metadata if specified ...
        if (sse != null) {
            metadata.setSSEAlgorithm(sse);
        }

        InputStream content = is;

        // if the content length is not specified, the AmazonS3Client will let the entire stream get loaded
        // into memory (BAD) so write all the content to a local file to get the length, then stream that ...
        File temp = null;
        if (!lengthKnown) {
            try {
                temp = Files.createTempFile(null, null).toFile();
                try (final OutputStream fos = new FileOutputStream(temp)) {
                    metadata.setContentLength(IOUtils.copy(is, fos));
                }
                content = new FileInputStream(temp);
            } catch (final IOException e) {
                logger.warn("Error writing temporary file", e);
                throw new RuntimeException(e);
            }
        }

        try {
            amazonS3.putObject(bucket, prefixedLocation, content, metadata);
        } catch (final AmazonServiceException e) {
            final String message = "Error writing content to " + getRawUri(prefixedLocation);
            logger.warn(message, e);
            throw new RuntimeException(message, e);
        } finally {
            // if a temporary file was created, close the stream and delete the file
            if (!lengthKnown) {
                try {
                    content.close();
                } catch (final IOException e) {
                    logger.info("Failed to close temporary file stream", e);
                }
                if (!temp.delete()) {
                    logger.info("Failed to clean up temporary file " + temp.getPath());
                }
            }
        }
    }

    @Override
    public byte[] readResource(final String location) {
        //delegating to alternate writeResource, don't modify location
        try (final InputStream is = openResource(location)) {
            return StreamUtils.copyToByteArray(new BufferedInputStream(is));
        } catch (final IOException e) {
            final String prefixedLocation = prefixedLocation(location);
            final String msg = "Error reading content from " + bucket + prefixedLocation;
            logger.warn(msg, e);
            throw new RuntimeException(msg, e);
        }
    }

    @Override
    public InputStream openResource(final String location) {
        final String prefixedLocation = prefixedLocation(location);
        try {
            return amazonS3.getObject(bucket, prefixedLocation).getObjectContent();
        } catch (final AmazonServiceException e) {
            if (e.getStatusCode() == 404 || e.getStatusCode() == 301) {
                throw new IllegalArgumentException("Invalid resource location " + prefixedLocation);
            }
            final String msg = "Amazon error reading content from " + bucket + prefixedLocation;
            logger.warn(msg, e);
            throw e;
        }
    }

    @Override
    public Properties readProperties(final String location) {
        final String prefixedLocation = prefixedLocation(location);
        final Properties properties = new Properties();

        final ObjectMetadata metadata = amazonS3.getObjectMetadata(bucket, prefixedLocation);
        for (final Map.Entry<String, String> entry : metadata.getUserMetadata().entrySet()) {
            properties.setProperty(entry.getKey(), entry.getValue());
        }
        // inject S3-specific properties
        if (metadata.getContentType() != null && !properties.containsKey(Headers.CONTENT_TYPE)) {
            properties.setProperty(Headers.CONTENT_TYPE, metadata.getContentType());
        }
        if (metadata.getContentLength() > 0 && !properties.containsKey(Headers.CONTENT_LENGTH)) {
            properties.put(Headers.CONTENT_LENGTH, metadata.getContentLength());
        }
        if (metadata.getLastModified() != null && !properties.containsKey(Headers.LAST_MODIFIED)) {
            properties.put(Headers.LAST_MODIFIED, metadata.getLastModified());
        }
        // inject the RawURI
        properties.put(ArchiveService.RawURI, getRawUri(location));

        return properties;
    }

    @Override
    public void writeProperties(final String location, final Properties properties) {
        final String prefixedLocation = prefixedLocation(location);
        final ObjectMetadata existingMetadata = amazonS3.getObjectMetadata(bucket, prefixedLocation);
        final ObjectMetadata newMetadata = mapPropertiesToObjectMetadata(properties, existingMetadata);

        final CopyObjectRequest request = new CopyObjectRequest(bucket, prefixedLocation, bucket, prefixedLocation)
                .withNewObjectMetadata(newMetadata);

        amazonS3.copyObject(request);
    }

    @Override
    public void delete(final String location) {
        final String prefixedLocation = prefixedLocation(location);
        ObjectListing listing = amazonS3.listObjects(bucket, prefixedLocation);
        if (listing.getObjectSummaries().isEmpty()) {
            throw new IllegalArgumentException("Invalid location " + prefixedLocation);
        }

        final DeleteObjectsRequest request = new DeleteObjectsRequest(bucket);
        while (true) {
            request.setKeys(listing.getObjectSummaries().stream()
                    .map(S3ObjectSummary::getKey)
                    .map(k -> new DeleteObjectsRequest.KeyVersion(k, null))
                    .collect(toList()));

            amazonS3.deleteObjects(request);

            if (listing.isTruncated()) {
                listing = amazonS3.listNextBatchOfObjects(listing);
            } else {
                break;
            }
        }
    }

    @Override
    public boolean exists(final String location) {
        final String prefixedLocation = prefixedLocation(location);
        return amazonS3.doesObjectExist(bucket, prefixedLocation);
    }

    private ObjectMetadata mapPropertiesToObjectMetadata(final Properties properties) {
        return mapPropertiesToObjectMetadata(properties, new ObjectMetadata());
    }

    private ObjectMetadata mapPropertiesToObjectMetadata(final Properties properties, final ObjectMetadata metadata) {
        if (properties != null) {
            for (final Map.Entry<Object, Object> entry : properties.entrySet()) {
                final String key = (String) entry.getKey();

                // Extract S3-specific properties into appropriate metadata and all other
                // properties into user metadata. NOTE: S3 metadata must be ascii-only (because
                // the SDK uses REST) so discard any non-ascii values.
                if (Headers.CONTENT_TYPE.equalsIgnoreCase(key)) {
                    metadata.setContentType((String) entry.getValue());
                } else if (Headers.CONTENT_LENGTH.equalsIgnoreCase(key)) {
                    metadata.setContentLength((Long) entry.getValue());
                } else if (Headers.LAST_MODIFIED.equalsIgnoreCase(key)) {
                    metadata.setLastModified((Date) entry.getValue());
                } else {
                    final String value = entry.getValue().toString();
                    if (CharMatcher.ascii().matchesAllOf(value)) {
                        metadata.addUserMetadata(key, value);
                    } else {
                        logger.info("Discarding non-ascii object metadata {}={}", key, value);
                    }
                }
            }
        }

        return metadata;
    }
}
